\chapter{Paging}

\section{Deterministische Algorithmen}

\subsection{Markierungsalgorithmen:}
$\sigma = (\overbrace{1, 2, 4, 2, 1}^{Phase 1},\overbrace{3, 5, 2, 3, 5}^{Phase 2},\overbrace{1, 2, 3}^{Phase 3},\overbrace{4}^{Phase 4})$



\textbf{Theorem 2.1.} LRU und FWF sind Markierungsalgorithmen

\textit{Beweis:} Widerspruchsbeweis: In der Phase müsste auf $k + 1$ verschiedene Seiten zugegriffen werden, damit eine markierte Seite verdrängt wird. (Widerspruch!)



\textbf{Theorem 2.2.} Jeder Markierungsalgorithmus ist strikt k-kompetitiv

\textit{Beweis:}
\begin{enumerate}
\item Fall: es gibt nur eine Phase: keine Seite wird jemals verdrängt: Markierungsalgorithmus ist optimal
\item Fall: es gibt mind. 2 Phasen: Kosten $\le l \cdot k$ (Anzahl Phasen mal Anzahl versch. Seiten / Phase).
\end{enumerate}
Annahme: opt. Offline Algo. macht mind. $(k + l - 2)$ Seitenfehler ($k$ in der ersten Phase, in jeder weiteren Phase (außer in der letzten) mind. einen Seitenfehler).

Teilsequenzen $(k=3)$:

$\sigma = (\overbrace{1, 2, 4, 2, 1}^{Phase 1},\overbrace{3, 5, 2, 3, 5}^{Phase 2},\overbrace{1, 2, 3}^{Phase 3},\overbrace{4}^{Phase 4})$\\
$\sigma = (1, 2, 4, 2, 1, \overbracket{3}^{x}, \underbracket{5, 2, 3, 5, 1}_{T1}, \underbracket{2, 3, 4}_{T2})$

pro Teilsequenz mind. 1 Seitenfehler, da z.B. in T1 $k$ Seiten sind, die sich von $x$ unterscheiden $\to$ 1 Seitenfehler.
Also: $\omega_{A}(\sigma) \le l \cdot k \le (k + l - 2) \cdot k \le \textrm{OPT}(\sigma) \cdot k$



\textbf{Korollar 2.3.} LRU und FWF sind strikt k-kompetitiv



\textbf{Theorem 2.4.} LFU und LIFO sind nicht kompetitiv
\textit{Beweis:} Gebe Gegenbeispiel an:

$\sigma = \left(1^l, 1^l, ..., (k-1)^l, (k, k+1)^l\right)$\\
$\Rightarrow k - 1 + 2(l - 1)$ Seitenfehler

\begin{align*}
\omega_{\textrm{LFU}}(\sigma) = \omega_{\textrm{LIFO}}(\sigma) &> r \cdot \textrm{OPT}(\sigma + \tau)\\
\Leftrightarrow k - 1 + 2 (l - 1) &> r \cdot (k + 1) + \tau \textrm{ für hinreichend große } l
\end{align*}



\textbf{Theorem 2.5.} Es gibt für kein $r < k$ einen deterministischen $r$-kompetitiven online Algorithmus für das Paging-Problem

\textit{Beweis:} Konstruiere Eingabe für bel. online Algo A: $\sigma_{1}$, $\sigma_{2}$, ..., $\sigma_{k}$: k verschiedene Seitem. Also hat sowohl A als auch opt. offline Algo k Seitenfehler.\\
Für $\sigma_{k + 1}$, ..., $\sigma_{k + l}$ gilt: Es kommt immer die Seite, die A vorher aus dem Cach geschmissen hat. Also macht A hier k + l Seitenfehler; LFD hat nur $\omega_{LFD}$($\sigma$) $\le$ k + 1 + $\tfrac{l}{k}$ Seitenfehler. \\
Da LFD mind. so viele Fehler macht wie OPT gilt: $\omega_{A}$($\sigma$) = k + l $>$ r $\cdot$ ( k + 1 + $\tfrac{l}{k}$) + $\tau$ $\ge$ r $\cdot$ $\omega_{LFO}$($\sigma$) + $\tau$ \\
 $\Rightarrow$  $\omega_{A}$($\sigma$) $>$ r $\cdot$ OPT($\sigma$) $\cot$ r


\subsection{Untere Schranken}


\subsection{Optimaler Offline-Algorithmus}

\textbf{Theorem 2.6.} LFT ist ein opt. offline Algorithmus für das Paging-Problem

\textit{Beweis mit Lemma 2.7}:

\textbf{Lemma 2.7.} Sei A ein bel. offline Algo, der sich auf Eingabe $\sigma$ anders Verhält als LFD uns sei $\sigma_{t}$ der erste Seitenzugriff, bei dem sich A und LFD unterscheiden. Dann ex. Algo B mit folgenden Eingenschaften:
\begin{enumerate}
\item B verhält sich auf $\sigma_{1}, ..., \sigma_{t - 1}$ genau wie A
\item Bei $\sigma_{t}$ verdrängt B die Seite, bei der der mächste Zugriff am weitesten weg ist
\item B verursacht auf $\sigma$ höchstens so viele Fehler wie Algo A
\end{enumerate}

\textit{Beweis Theorem 2.6:}\\
Man verwendet (höchstens n - mal) Lemma 2.7 so oft hintereinander an, bis sich Algo B genauso verhält wie LFD. Da dieser dann (laut Lemma) höchstens so viele Fehler macht wie OPT ist LFD optimal.\\
$\omega_{LFD}(\sigma) = \omega_{A_{n}}(\sigma) \le \omega_{A_{n-1}}(\sigma) \le ... \le \omega_{A_{1}}(\sigma) \le \omega_{OPT}(\sigma)$ \\

\textit{Beweis Lemma 2.7:}\\
Wir konstruieren nun Algo B: \\
Auf der Sequent $\sigma_{1}, ..., \sigma_{t-1}$ verhalten sich die Algorithmen A und B gleich. bei $\sigma_{t}$ machen beide einen Seitenfehler, verdrängen aber unterschieldiche Seiten aus dem Cach.
\\
\\
\\
TODO: !!!Beweis Lemma 2.7!!!
\\
\\
\\

\subsection{Zusammenfassung der Ergebnisse}

\begin{tabular}{| l | l |}
\hline
LRU (least-recently-used)   & strikt $k$-kompetitiv da Markierungsalgorithmus \\ \hline
FWF (flush-when-full)     & strikt $k$-kompetitiv da Markierungsalgorithmus \\ \hline
FIFO (first-in-first-out)   & kein Markierungsalgorithmus, dennoch $k$-kompetitiv \\ \hline
LFU (least-frequently-used)   & nicht kompetitiv\\ \hline
LIFO (last-in-first-out)    & nicht kompetitiv\\ \hline
LFD (longest-forward-distance)& optimaler Offline-Algorithmus \\ \hline
\end{tabular}



\section{Randomisierte Algorithmen}


\textbf{Definition 2.8} Ein randomisierter Online-Algorithmus $A$ für ein Minimierungsproblem $\Pi$ erreicht einen kompetitiven Faktor von $r \ge 1$, wenn es eine Konstante $r \in \mathbb{R}$ gibt, sodass
$$E[w_A(\sigma)] \leq r \cdot \textrm{OPT}(\sigma) + \tau$$
für alle Instanzen $\sigma \in I_\Pi$ gilt. Gilt diese Ungleichung sogar für $\tau = 0$, so ist $A$ strikt $r$-kompetitiv.

Der Unterschied zu Definition 1.1 besteht lediglich darin, dass wir hier den Erwartungswert der Kosten nutzen, da diese vom Zufall abhängen.

\subsection{Potentialfunktionen}

\textbf{Theorem 2.9} Es sei $A$ ein Online-Algorithmus und $r \geq 1$. Gibt es eine Konstante $b \geq 0$ und eine Potentialfunktion $\Phi$, die die folgenden drei Bedingungen für jede Eingabe $\sigma$ erfüllt, so erreicht Algorithmus $A$ einen kompetitiven Faktor von $r$.
\begin{enumerate}
\item Für jedes $i \geq 1$ gilt $E[a_i] \leq r \cdot \textrm{OPT}_i$.\\
(Die amortisierten Kosten sind höchstens $r$ mal größer als die Kosten von OPT.)
\item Es gilt $E[\Phi_0] \leq b$.\\
(Der Kontostand ist zu Beginn durch eine Konstante nach oben beschränkt.)
\item Für jedes $i \geq 1$ gilt $E[\Phi_i] \geq -b$.\\
(Zu keinem Zeitpunkt wird das Konto stärker als eine Konstante überzogen.)
\end{enumerate}

\textit{Beweisidee:} Da der Startkontostand bzw. das Überziehen des Kontos durch eine Konstante beschränkt sind, kann dies durch das $\tau$ in der Ungleichung des kompetitiven Faktors ausgeglichen werden.


\subsection{Analyse von RANDOM}


\textbf{Theorem 2.10} Der Algorithmus RANDOM ist $k$-kompetitiv.

\textit{Beweisidee:} To be done...



\textbf{Lemma 2.11} Es sei $X$ eine geometrisch verteilte Zufallsvariable mit Parameter $p$ und es sei $n \in \mathbb{N}$. Für die Zufallsvariable $Y = min\{X,n\}$ gilt $$E[Y] = \frac{1-(1-p)^n}{p}$$

\textit{Vermutlich ist dieses Lemma für die Prüfung nicht relevant, da es sich nur um Rechnerei handelt.}



\textbf{Theorem 2.12} Der kompetitive Faktor von RANDOM beträgt mindestens $k$.

\textit{Beweisidee:} Wir betrachten die Sequenz $$\sigma = \left((a_1,...,a_k),(b_1,a_2,...,a_k)^l,(b_2,a_2,...,a_k)^l,...,(b_m,a_2,...,a_k)^l\right)$$.

Bei der Anzahl der Seitenfehler in einer Teilsequenz $(b_i,a_2,...,a_k)^l$ handelt es sich hier um eine bei $l$ abgeschnittene geometrische Zufallsvariable mit Parameter $1/k$. Somit können wir Lemma 2.11 anwenden...


\subsection{Analyse von MARK}

\subsection{Untere Schranke für randomisierte Online-Algorithmen}
